import os, getpass
from langchain_openai import ChatOpenAI
import operator
from typing import Annotated
from typing_extensions import TypedDict
from pydantic import BaseModel
from langgraph.constants import Send
from IPython.display import Image
from langgraph.graph import END, StateGraph, START
from dotenv import load_dotenv 

# loading variables from .env file
load_dotenv() 

# Utility function to set an environment variable if it is not already set. If the variable is not set, it will prompt the user to enter the value interactively.
    
#     Args:
#         var (str): The name of the environment variable to set.
def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

# Sets the environment variables OPENAI_API_KEY and LANGCHAIN_API_KEY if they are not already set, prompting the user to enter the values interactively. Also sets the environment variables LANGCHAIN_TRACING_V2 to "true" and LANGCHAIN_PROJECT to "langchain-academy".
_set_env("OPENAI_API_KEY")
_set_env("LANGCHAIN_API_KEY")
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "langchain-academy"

# Initializes a ChatOpenAI model with the specified parameters. The `model` parameter sets the name of the OpenAI model to use, and the `temperature` parameter controls the randomness of the model's output.
model = ChatOpenAI(model="gpt-4o", temperature=0)

# These are prompt templates used to generate topics, jokes, and the best joke from a set of jokes. The `subjects_prompt` template is used to generate a list of 3 sub-topics related to the overall topic. The `joke_prompt` template is used to generate a joke about a specific subject. The `best_joke_prompt` template is used to select the best joke from a set of jokes about a specific topic.
subjects_prompt = """Generate a list of 3 sub-topics that are all related to this overall topic: {topic}."""
joke_prompt = """Generate a joke about {subject}"""
best_joke_prompt = """Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first joke. Jokes: \n\n  {jokes}"""

# These classes are used to define the data structures for the joke generation and selection process:

# - `Subjects`: Represents a list of subject strings related to a given topic.
# - `BestJoke`: Represents the selected best joke, containing the ID of the best joke.
# - `OverallState`: Represents the overall state of the joke generation process, including the topic, list of subjects, list of generated jokes, and the selected best joke.
# - `JokeState`: Represents the state for generating a single joke, including the subject.
# - `Joke`: Represents a single joke, containing the joke text.
class Subjects(BaseModel):
    subjects: list[str]

class BestJoke(BaseModel):
    id: int
    
class OverallState(TypedDict):
    topic: str
    subjects: list
    jokes: Annotated[list, operator.add]
    best_selected_joke: str

class JokeState(TypedDict):
    subject: str

class Joke(BaseModel):
    joke: str

# Generates a list of 3 sub-topics related to the given overall topic. The sub-topics are generated using the `subjects_prompt` template, which is filled with the current topic from the `OverallState`. The generated list of sub-topics is returned as the `subjects` field in the function's output.    
def generate_topics(state: OverallState):
    prompt = subjects_prompt.format(topic=state["topic"])
    response = model.with_structured_output(Subjects).invoke(prompt)
    return {"subjects": response.subjects}

# Generates a list of "Send" actions to trigger the "generate_joke" node for each subject in the given OverallState. This function is used to transition the state graph from the "generate_topics" node to the "generate_joke" node, creating a separate "generate_joke" action for each subject generated by the "generate_topics" node.
def continue_to_jokes(state: OverallState):
    return [Send("generate_joke", {"subject": s}) for s in state["subjects"]]

# Generates a joke about the given subject using the `joke_prompt` template. The generated joke is returned as a list with a single element.

#     Args:
#         state (JokeState): The state for generating a single joke, containing the subject.
    
#     Returns:
#         dict: A dictionary containing the generated joke in the "jokes" field.
def generate_joke(state: JokeState):
    prompt = joke_prompt.format(subject=state["subject"])
    response = model.with_structured_output(Joke).invoke(prompt)
    return {"jokes": [response.joke]}

# Selects the best joke from the list of generated jokes based on the given topic.
    
#     Args:
#         state (OverallState): The overall state of the joke generation process, including the topic, list of subjects, list of generated jokes, and the selected best joke.
    
#     Returns:
#         dict: A dictionary containing the selected best joke in the "best_selected_joke" field.
def best_joke(state: OverallState):
    jokes = "\n\n".join(state["jokes"])
    prompt = best_joke_prompt.format(topic=state["topic"], jokes=jokes)
    response = model.with_structured_output(BestJoke).invoke(prompt)
    return {"best_selected_joke": state["jokes"][response.id]}

# Construct the graph: here we put everything together to construct our graph
graph = StateGraph(OverallState)
graph.add_node("generate_topics", generate_topics)
graph.add_node("generate_joke", generate_joke)
graph.add_node("best_joke", best_joke)
graph.add_edge(START, "generate_topics")
graph.add_conditional_edges("generate_topics", continue_to_jokes, ["generate_joke"])
graph.add_edge("generate_joke", "best_joke")
graph.add_edge("best_joke", END)

# Compile the graph
app = graph.compile()

# Iterates over the output of the `app.stream()` function, which is likely a sequence of dictionaries representing the generated jokes, and prints each item.
for s in app.stream({"topic": "animals"}):
    print(s)